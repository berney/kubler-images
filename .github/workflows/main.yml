name: Kubler Build
on:
  push:
    branches:
      - main
  workflow_dispatch:

# Jobs run in parallel
# Jobs are independent with separate file systems, IP addresses, etc.
jobs:
  setup:
    name: Setup Kubler
    runs-on: ubuntu-latest
    outputs:
      portage_date: ${{ steps.portage_date.outputs.portage_date }}
      bob_stage3_date: ${{ steps.stage3.outputs.bob_stage3_date }} }}
      bob_musl_stage3_date: ${{ steps.stage3.outputs.bob_musl_stage3_date }} }}
    env:
      KUBLER_IMAGE: ghcr.io/${{ github.repository }}
    steps:
      - name: Set up QEMU
        id: qemu
        uses: docker/setup-qemu-action@v3
        with:
          image: tonistiigi/binfmt:latest
          platforms: all

      - name: üêã Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v3
        with:
          # This breaks kubler https://github.com/edannenberg/kubler/issues/215
          # Sets up `docker build` command as an alias to `docker buildx` (default `false`)
          install: true

      - name: üêã Docker Login
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}
          # this is the default, end of job will logout
          #logout: true

      - name: Check out repository code
        uses: actions/checkout@v4

      - name: üêãüç≥ Docker Bake Kubler
        #if: ${{ steps.portage-pull.outcome == 'failure' }}
        uses: docker/bake-action@v4
        with:
          push: true
          set: |
            kubler.tags=ghcr.io/${{ github.repository }}

      - name: üë∑ Portage Date
        id: portage_date
        run: |
          set -eux
          PORTAGE_DATE=$(docker run --rm -e TERM=dumb -w /root/.kubler "${KUBLER_IMAGE}" kubler portage)
          echo "portage_date=$PORTAGE_DATE"
          echo "portage_date=$PORTAGE_DATE" >> $GITHUB_OUTPUT

      - name: üë∑ Get STAGE3_DATE
        id: stage3_date
        run: |
          set -eux
          docker run --rm -w /root/.kubler/namespaces/kubler "${KUBLER_IMAGE}" grep '^STAGE3_DATE=' builder/bob/build.conf
          docker run --rm -w /root/.kubler/namespaces/kubler "${KUBLER_IMAGE}" grep '^STAGE3_DATE=' builder/bob-musl/build.conf
          bob=$(docker run --rm -w /root/.kubler/namespaces/kubler "${KUBLER_IMAGE}" sed -n "s/^STAGE3_DATE='\(202[34][01][0-9]\{3\}T[0-9]\{6\}Z\)'$/\\1/p" builder/bob/build.conf)
          bob_musl=$(docker run --rm -w /root/.kubler/namespaces/kubler "${KUBLER_IMAGE}" sed -n "s/^STAGE3_DATE='\(202[34][01][0-9]\{3\}T[0-9]\{6\}Z\)'$/\\1/p" builder/bob-musl/build.conf)
          if [[ ("$bob" != "$bob_musl") ]]; then
            echo "WARNING: bob and bob-musl have different STAGE3_DATE"
          fi
          echo "bob_stage3_date=$bob" >> $GITHUB_OUTPUT
          echo "bob_musl_stage3_date=$bob_musl" >> $GITHUB_OUTPUT


  kubler-portage:
    runs-on: ubuntu-latest
    needs: setup
    outputs:
      portage_image: ${{ steps.portage_image.outputs.portage_image }}
    env:
      KUBLER_IMAGE: ghcr.io/${{ github.repository }}
      PORTAGE_DATE: ${{ needs.setup.outputs.portage_date }}
    steps:
      - name: Set up QEMU
        id: qemu
        uses: docker/setup-qemu-action@v3
        with:
          image: tonistiigi/binfmt:latest
          platforms: all

      - name: üêã Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v3
        with:
          # This breaks kubler https://github.com/edannenberg/kubler/issues/215
          # Sets up `docker build` command as an alias to `docker buildx` (default `false`)
          install: true

      - name: üêã Docker Login
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - uses: oras-project/setup-oras@v1

      - run: |
          oras version

      - name: Check out repository code
        uses: actions/checkout@v4

      - name: üêãüç≥ Docker Bake Kubler portage - set PORTAGE_IMAGE env vars
        run: |
          set -eux
          TMP_PORTAGE_IMAGE=ghcr.io/"${GITHUB_REPOSITORY}"/tmp/portage:"${PORTAGE_DATE}"
          PORTAGE_IMAGE=ghcr.io/"${GITHUB_REPOSITORY}"/portage:"${PORTAGE_DATE}"
          echo "TMP_PORTAGE_IMAGE=$TMP_PORTAGE_IMAGE" >> $GITHUB_ENV
          echo "PORTAGE_IMAGE=$PORTAGE_IMAGE" >> $GITHUB_ENV

      - name: üêã Docker Pull Portage
        id: portage-pull
        continue-on-error: true
        run: |
          set -eu
          docker pull "$PORTAGE_IMAGE"

      # We always test, even if we pulled
      # A pushed image should have been tested before being pushed.
      # But re-testing for extra safety and in case tests have changed in between.
      - name: üêãüç≥ Docker Bake Kubler portage - test pulled
        id: portage-pull-test
        if: ${{ steps.portage-pull.outcome == 'success' }}
        continue-on-error: true
        run: |
          set -eux
          docker run --rm "${PORTAGE_IMAGE}" grep TIMESTAMP /var/db/repos/gentoo/Manifest
          cd bob-portage || exit 1
          docker run --rm -v /run/docker.sock:/run/docker.sock -v "$(pwd):/src:ro" -w /src -e CONTAINER_MODE=entrypoint "$KUBLER_IMAGE" dgoss run -w /goss --entrypoint /goss/goss "${PORTAGE_IMAGE}" validate --format documentation --color

      - name: üêãüç≥ Docker Bake Kubler portage - list targets
        if: ${{ steps.portage-pull.outcome == 'failure' || steps.portage-pull-test.outcome == 'failure' }}
        uses: docker/bake-action/subaction/list-targets@v4
        with:
          workdir: bob-portage

      - name: üêãüç≥ Docker Bake Kubler portage
        if: ${{ steps.portage-pull.outcome == 'failure' || steps.portage-pull-test.outcome == 'failure' }}
        uses: docker/bake-action@v4
        with:
          workdir: bob-portage
          push: true
          set: |
            kubler-portage.tags=${{ env.TMP_PORTAGE_IMAGE }}
            kubler-portage.cache-from=type=gha,scope=portage
            kubler-portage.cache-to=type=gha,scope=portage

      - name: üêãüç≥ Docker Bake Kubler portage - test baked
        if: ${{ steps.portage-pull.outcome == 'failure' || steps.portage-pull-test.outcome == 'failure' }}
        run: |
          set -eux
          docker run --rm "${TMP_PORTAGE_IMAGE}" grep TIMESTAMP /var/db/repos/gentoo/Manifest
          cd bob-portage || exit 1
          docker run --rm -v /run/docker.sock:/run/docker.sock -v "$(pwd):/src:ro" -w /src -e CONTAINER_MODE=entrypoint "$KUBLER_IMAGE" dgoss run -w /goss --entrypoint /goss/goss "${TMP_PORTAGE_IMAGE}" validate --format documentation --color

      - name: üêãüç≥ Docker Bake Kubler portage - oras cp
        if: ${{ steps.portage-pull.outcome == 'failure' || steps.portage-pull-test.outcome == 'failure' }}
        run: |
          set -eux
          oras cp -v "$TMP_PORTAGE_IMAGE" "$PORTAGE_IMAGE"

      - name: Output PORTAGE_IMAGE
        id: portage_image
        run: |
          set -eux
          echo "portage_image=${PORTAGE_IMAGE}" >> $GITHUB_OUTPUT

  stage3:
    runs-on: ubuntu-latest
    needs:
      - setup
      - kubler-portage
    env:
      KUBLER_IMAGE: ghcr.io/${{ github.repository }}
      PORTAGE_DATE: ${{ needs.setup.outputs.portage_date }}
      PORTAGE_IMAGE: ${{ needs.kubler-portage.outputs.portage_image }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: bob
            stage3:
              base: gentoo/stage3:hardened-nomultilib
              tmp_image: ghcr.io/${{ github.repository }}/tmp/stage3-amd64-hardened-nomultilib-openrc:${{ needs.setup.outputs.portage_date }}
              image: ghcr.io/${{ github.repository }}/stage3-amd64-hardened-nomultilib-openrc:${{ needs.setup.outputs.portage_date }}
              cache: stage3-amd64-hardened-nomultilib-openrc
              goss: stage3/amd64-hardened-nomultilib-openrc
            core:
              tmp_image: ghcr.io/${{ github.repository }}/tmp/bob-core:${{ needs.setup.outputs.portage_date }}
              image: ghcr.io/${{ github.repository }}/bob-core:${{ needs.setup.outputs.portage_date }}
              cache: bob-core
              goss: core/bob-core
          - name: bob-musl
            stage3:
              base: gentoo/stage3:musl-hardened
              tmp_image: ghcr.io/${{ github.repository }}/tmp/stage3-amd64-musl-hardened:${{ needs.setup.outputs.portage_date }}
              image: ghcr.io/${{ github.repository }}/stage3-amd64-musl-hardened:${{ needs.setup.outputs.portage_date }}
              cache: stage3-amd64-musl-hardened
              goss: stage3/amd64-musl-hardened
            core:
              tmp_image: ghcr.io/${{ github.repository }}/tmp/bob-musl-core:${{ needs.setup.outputs.portage_date }}
              image: ghcr.io/${{ github.repository }}/bob-musl-core:${{ needs.setup.outputs.portage_date }}
              cache: bob-musl-core
              goss: core/bob-musl-core
    steps:
      - name: Set up QEMU
        id: qemu
        uses: docker/setup-qemu-action@v3
        with:
          image: tonistiigi/binfmt:latest
          platforms: all

      - name: üêã Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v3
        with:
          # This breaks kubler https://github.com/edannenberg/kubler/issues/215
          # Sets up `docker build` command as an alias to `docker buildx` (default `false`)
          install: true

      - name: üêã Docker Login
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Check out repository code
        uses: actions/checkout@v4

      - uses: oras-project/setup-oras@v1

      - name: üêã Docker Pull stage3
        id: stage3-pull
        continue-on-error: true
        run: |
          set -eu
          docker pull "${{ matrix.stage3.image }}"

      - name: üêãüç≥ Docker Bake Kubler stage3 - test pulled
        id: stage3-pull-test
        if: ${{ steps.stage3-pull.outcome == 'success' }}
        continue-on-error: true
        run: |
          set -eux
          docker run --rm "${{ matrix.stage3.image }}" cat /etc/gentoo-release
          docker run --rm "${{ matrix.stage3.image }}" sh -c "grep -E 'Latest|stage3' /latest-stage3*.txt"
          docker run --rm "${{ matrix.stage3.image }}" eselect profile show
          cd "${{ matrix.stage3.goss }}" || exit 1
          docker run --rm -v /run/docker.sock:/run/docker.sock -v "$(pwd):/src:ro" -w /src -e CONTAINER_MODE=entrypoint "$KUBLER_IMAGE" dgoss run -w /goss --entrypoint /goss/goss "${{ matrix.stage3.image }}" validate --format documentation --color

      - name: üêãüç≥ Docker Bake Kubler stage3 - list targets
        if: ${{ steps.stage3-pull.outcome == 'failure' || steps.stage3-pull-test.outcome == 'failure' }}
        uses: docker/bake-action/subaction/list-targets@v4
        with:
          workdir: bob-stage3

      - name: üêãüç≥ Docker Bake Kubler stage3
        if: ${{ steps.stage3-pull.outcome == 'failure' || steps.stage3-pull-test.outcome == 'failure' }}
        uses: docker/bake-action@v4
        with:
          workdir: bob-stage3
          push: true
          # In the `docker-bake.hcl`
          # There is a variable `BASE_TAG` and `BASE_IMAGE`. `BASE_IMAGE` interpolates `BASE_TAG`i
          # These can be set with env vars when using `docker buildx bake` command
          # For the gentoo-stage3 target there's no `BASE_TAG` arg, only `BASE_IMAGE` which defaults to `BASE_IMAGE` var
          # When using bake-action we need to set the `BASE_IMAGE` arg, setting `BASE_TAG` arg won't do what we want.
          set: |
            gentoo-stage3.args.BASE_IMAGE=${{ matrix.stage3.base }}
            gentoo-stage3.args.PORTAGE=${{ env.PORTAGE_IMAGE }}
            gentoo-stage3.tags=${{ matrix.stage3.tmp_image }}
            gentoo-stage3.cache-from=type=gha,scope=portage
            gentoo-stage3.cache-from=type=gha,scope=${{ matrix.stage3.cache }}
            gentoo-stage3.cache-to=type=gha,scope=${{ matrix.stage3.cache }}

      - name: üêãüç≥ Docker Bake Kubler stage3 - test baked
        if: ${{ steps.stage3-pull.outcome == 'failure' || steps.stage3-pull-test.outcome == 'failure' }}
        run: |
          set -eux
          docker run --rm "${{ matrix.stage3.tmp_image }}" cat /etc/gentoo-release
          docker run --rm "${{ matrix.stage3.tmp_image }}" sh -c "grep -E 'Latest|stage3' /latest-stage3*.txt"
          docker run --rm "${{ matrix.stage3.tmp_image }}" eselect profile show
          cd "${{ matrix.stage3.goss }}" || exit 1
          docker run --rm -v /run/docker.sock:/run/docker.sock -v "$(pwd):/src:ro" -w /src -e CONTAINER_MODE=entrypoint "$KUBLER_IMAGE" dgoss run -w /goss --entrypoint /goss/goss "${{ matrix.stage3.tmp_image }}" validate --format documentation --color

      - name: üêãüç≥ Docker Bake Kubler stage3 - oras cp
        if: ${{ steps.stage3-pull.outcome == 'failure' || steps.stage3-pull-test.outcome == 'failure' }}
        run: |
          set -eux
          oras cp -v "${{ matrix.stage3.tmp_image }}" "${{ matrix.stage3.image }}"

      - name: üêã Docker Pull bob-core
        id: bob-core-pull
        continue-on-error: true
        run: |
          set -eu
          docker pull "${{ matrix.core.image }}"

      - name: üêãüç≥ Docker Bake Kubler bob-core - test pulled
        id: bob-core-pull-test
        if: ${{ steps.bob-core-pull.outcome == 'success' }}
        run: |
          set -eux
          docker run --rm "${{ matrix.core.image }}" cat /etc/gentoo-release
          docker run --rm "${{ matrix.core.image }}" sh -c "grep -E 'Latest|stage3' /latest-stage3*.txt"
          docker run --rm "${{ matrix.core.image }}" eselect profile show
          docker run --rm "${{ matrix.core.image }}" ls -l /var/cache
          cd "${{ matrix.core.goss }}" || exit 1
          docker run --rm -v /run/docker.sock:/run/docker.sock -v "$(pwd):/src:ro" -w /src -e CONTAINER_MODE=entrypoint "${KUBLER_IMAGE}" dgoss run -w /goss --entrypoint /goss/goss "${{ matrix.core.image }}" validate --format documentation --color

      - name: üêãüç≥ Docker Bake Kubler bob-core - list targets
        if: ${{ steps.bob-core-pull.outcome == 'failure' || steps.bob-core-pull-test.outcome == 'failure' }}
        uses: docker/bake-action/subaction/list-targets@v4
        with:
          workdir: bob-core

      - name: üêãüç≥ Docker Bake Kubler bob-core
        if: ${{ steps.bob-core-pull.outcome == 'failure' || steps.bob-core-pull-test.outcome == 'failure' }}
        uses: docker/bake-action@v4
        with:
          workdir: bob-core
          push: true
          set: |
            core.args.BASE_IMAGE=${{ matrix.stage3.image }}
            core.tags=${{ matrix.core.tmp_image }}
            core.cache-from=type=gha,scope=portage
            core.cache-from=type=gha,scope=${{ matrix.stage3.cache }}
            core.cache-from=type=gha,scope=${{ matrix.core.cache }}
            core.cache-to=type=gha,scope=${{ matrix.core.cache }}

      - name: üêãüç≥ Docker Bake Kubler bob-core - test baked
        if: ${{ steps.bob-core-pull.outcome == 'failure' || steps.bob-core-pull-test.outcome == 'failure' }}
        run: |
          set -eux
          docker run --rm "${{ matrix.core.tmp_image }}" cat /etc/gentoo-release
          docker run --rm "${{ matrix.core.tmp_image }}" sh -c "grep -E 'Latest|stage3' /latest-stage3*.txt"
          docker run --rm "${{ matrix.core.tmp_image }}" eselect profile show
          docker run --rm "${{ matrix.core.tmp_image }}" ls -l /var/cache
          cd "${{ matrix.core.goss }}" || exit 1
          docker run --rm -v /run/docker.sock:/run/docker.sock -v "$(pwd):/src:ro" -w /src -e CONTAINER_MODE=entrypoint "${KUBLER_IMAGE}" dgoss run -w /goss --entrypoint /goss/goss "${{ matrix.core.tmp_image }}" validate --format documentation --color

      - name: üêãüç≥ Docker Bake Kubler bob-core - oras cp
        if: ${{ steps.bob-core-pull.outcome == 'failure' || steps.bob-core-pull-test.outcome == 'failure' }}
        run: |
          set -eux
          oras cp -v "${{ matrix.core.tmp_image }}" "${{ matrix.core.image }}"

  kubler:
    runs-on: ubuntu-latest
    needs:
      - setup
      - kubler-portage
      - stage3
    env:
      KUBLER_IMAGE: ghcr.io/${{ github.repository }}
      PORTAGE_IMAGE: ${{ needs.kubler-portage.outputs.portage_image }}
    steps:
      - run: echo "üéâ The job was automatically triggered by a ${{ github.event_name }} event."
      - run: echo "üêß This job is now running on a ${{ runner.os }} server hosted by GitHub!"
      - run: echo "üîé The name of your branch is ${{ github.ref }} and your repository is ${{ github.repository }}."

      - name: Check out repository code
        uses: actions/checkout@v4

      - run: echo "üí° The ${{ github.repository }} repository has been cloned to the runner."
      - run: echo "üñ•Ô∏è The workflow is now ready to test your code on the runner."

      - name: List files in the repository
        run: |
          ls ${{ github.workspace }}

      - name: üîé Inspect Runner
        run: |
          df -h
          free -m
          bash --version
          docker version
          docker info
          pwd
          echo $PATH
          type goss || true

      - name: Install goss from berne/goss
        #if: ${{ false }}
        run: |
          # This is a modified goss
          docker pull berne/goss
          docker create --name goss berne/goss
          docker cp goss:/bin/goss /usr/local/bin/
          docker rm goss
          type goss
          goss --version

      - name: Install dgoss
        #if: ${{ false }}
        run: |
          cp dgoss /usr/local/bin/

      - name: Update Docker Engine
        # Disable
        if: ${{ false }}
        run: |
          docker version
          docker info
          # Remove old packages
          for pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg || true; done
          sudo apt-get update
          sudo apt-get install ca-certificates curl gnupg
          ls -ld /etc/apt/keyrings || true
          ls -l /etc/apt/keyrings/docker.gpg || true
          sudo install -m 0755 -d /etc/apt/keyrings
          curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
          sudo chmod a+r /etc/apt/keyrings/docker.gpg
          ls -ld /etc/apt/sources.list.d || true
          ls -l /etc/apt/sources.list.d/ || true
          ls -l /etc/apt/sources.list.d/docker.list || true
          echo \
            "deb [arch="$(dpkg --print-architecture)" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
            "$(. /etc/os-release && echo "$VERSION_CODENAME")" stable" | \
            sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
          cat /etc/apt/sources.list.d/docker.list
          sudo apt-get update
          sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
          systemctl status docker
          sudo systemctl start docker
          docker version
          docker info
          docker run --rm hello-world

      - name: üë∑ Install Kubler
        run: |
          cd .. || exit 1

          ## Install from tarball
          #
          #curl -L https://github.com/edannenberg/kubler/archive/master.tar.gz | tar xz
          #ls -ld kubler-master
          #mv kubler-master kubler
          #ls -l kubler/bin
          #echo "$(pwd)/kubler/bin" >> $GITHUB_PATH

          ## Install from Git
          #
          git clone https://github.com/berney/kubler.git
          cd kubler || exit 1
          # Using my branch to pick-up fixes until PRs are merged
          #git checkout f-berne
          git checkout f-experiment-buildx-bake
          git describe --all --long --dirty
          #git checkout f-berne-bake
          ls -l bin
          echo "$(pwd)/bin" >> $GITHUB_PATH

      - name: üë∑ Kubler Version
        run: |
          export TERM
          kubler --help

      - name: üë∑ Kubler Inspect Terminal
        run: |
          echo "TERM=$TERM"
          echo $PATH
          pwd
          env
          # test term colors
          kubler dep-graph xxx || true
          echo "export TERM"
          export TERM
          kubler dep-graph xxx || true
          echo "export TERM=dumb"
          export TERM
          export TERM=dumb
          kubler dep-graph xxx || true
          echo "export TERM=xterm"
          export TERM=xterm
          kubler dep-graph xxx || true

      # Cache Versions are based off key and path, so differnt path's can use same key
      #
      # Caches are immutable, so need unique key to create a new cache
      # `restore-keys` provides a list to restore a cache when key doesn't match
      # If there's no exact match, the most recent cache that partially matches will be used
      #
      - name: Cache Kubler Downloads
        uses: actions/cache@v4
        with:
          path: ~/.kubler/downloads/
          key: kubler-${{ github.sha }}
          restore-keys: |
            kubler-

      - name: Cache Kubler Gentoo Distfiles
        uses: actions/cache@v4
        with:
          path: ~/.kubler/distfiles/
          key: kubler-${{ github.sha }}
          restore-keys: |
            kubler-

      - name: Cache Kubler Gentoo Packages
        uses: actions/cache@v4
        with:
          path: ~/.kubler/packages/
          key: kubler-${{ github.sha }}
          restore-keys: |
            kubler-

      - name: Set up QEMU
        id: qemu
        uses: docker/setup-qemu-action@v3
        with:
          image: tonistiigi/binfmt:latest
          platforms: all

      - name: üêã Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v3
        with:
          # This breaks kubler https://github.com/edannenberg/kubler/issues/215
          # Sets up `docker build` command as an alias to `docker buildx` (default `false`)
          install: true

      - name: üêã Inspect builder
        run: |
          echo "Name:      ${{ steps.buildx.outputs.name }}"
          echo "Endpoint:  ${{ steps.buildx.outputs.endpoint }}"
          echo "Status:    ${{ steps.buildx.outputs.status }}"
          echo "Flags:     ${{ steps.buildx.outputs.flags }}"
          echo "Platforms: ${{ steps.buildx.outputs.platforms }}"

      - name: üêã Docker Login
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: üêã Docker Buildx Inspect
        run: |
          docker version
          docker info
          docker buildx version
          docker buildx ls
          # `default` is the name of the normie docker builder
          docker buildx inspect default
          # The buildx builder is the default builder due to the `install: true` above
          docker buildx inspect "${{ steps.buildx.outputs.name }}"

      # When we use `docker buildx` and `docker bake` we want to be able to access images we built in prior steps
      # For this we need the containerd-snapshotter feature which is in beta
      - name: Docker Daemon Config - Enable Containerd Snapshotter
        run: |
          id -a
          ls -l /etc/docker/daemon.json
          # Old config
          jq . /etc/docker/daemon.json
          # First read old config before we clobber it
          CONFIG=$(jq '.features["containerd-snapshotter"] = true' /etc/docker/daemon.json)
          # Write new config - sudo tee to write to root owned file
          echo "$CONFIG" | sudo tee /etc/docker/daemon.json
          jq . /etc/docker/daemon.json
          systemctl status docker
          sudo systemctl restart docker
          systemctl status docker
          docker run --rm hello-world

      - name: üêã Docker Buildx Inspect Again
        run: |
          docker version
          docker info
          docker buildx version
          docker buildx ls
          # `default` is the name of the normie docker builder
          docker buildx inspect default
          # The buildx builder is the default builder due to the `install: true` above
          docker buildx inspect "${{ steps.buildx.outputs.name }}"

      - name: üë∑ Update Kubler (kubler-images, Gentoo Stage3)
        run: |
          export TERM
          ls -la ~/.kubler || true
          ls -la ~/.kubler/namespaces || true
          ls -la ~/.kubler/namespaces/kubler || true
          kubler update
          ls -la ~/.kubler || true
          ls -la ~/.kubler/namespaces || true
          ls -la ~/.kubler/namespaces/kubler || true

      - name: üë∑ Inspect Kubler Images
        run: |
          cd ~/.kubler/namespaces/kubler/ || exit 1
          git remote -v
          git status
          git ls-files -o
          git diff

      - name: üë∑ Add Custom Kubler Command(s)
        run: |
          echo "Kubler Commands (OG)"
          pwd
          ls -l
          tree -a -C ../kubler
          ls -l ../kubler
          ls -l ../kubler/cmd
          echo "Custom Kubler Commands"
          ls -l kubler/cmd
          rsync -avi kubler/cmd/* ../kubler/cmd/
          echo "Kubler Commands (now)"
          ls -l ../kubler/cmd

      - name: üîë Get Gentoo Portage GPG Key
        run: |
          # For Portage signatures
          #
          # Fingerprint with spaces `gpg -k --fingerprint --with-subkey-fingerprints E1D6ABB63BFCFB4BA02FDF1CEC590EEAC9189250`:
          #
          # pub   rsa4096/DB6B8C1F96D8BF6D 2011-11-25 [C] [expires: 2023-07-01]
          #       Key fingerprint = DCD0 5B71 EAB9 4199 527F  44AC DB6B 8C1F 96D8 BF6D
          #       uid                 [ unknown] Gentoo ebuild repository signing key (Automated Signing Key) <infrastructure@gentoo.org>
          #       uid                 [ unknown] Gentoo Portage Snapshot Signing Key (Automated Signing Key)
          #       sub   rsa4096/EC590EEAC9189250 2011-11-25 [S] [expires: 2023-07-01]
          #             Key fingerprint = E1D6 ABB6 3BFC FB4B A02F  DF1C EC59 0EEA C918 9250
          #
          # Fingerprint longkeyid no spaces `gpg -k --with-subkey-fingerprints E1D6ABB63BFCFB4BA02FDF1CEC590EEAC9189250`:
          #
          # pub   rsa4096/DB6B8C1F96D8BF6D 2011-11-25 [C] [expires: 2023-07-01]
          #       DCD05B71EAB94199527F44ACDB6B8C1F96D8BF6D
          #       uid                 [ unknown] Gentoo ebuild repository signing key (Automated Signing Key) <infrastructure@gentoo.org>
          #       uid                 [ unknown] Gentoo Portage Snapshot Signing Key (Automated Signing Key)
          #       sub   rsa4096/EC590EEAC9189250 2011-11-25 [S] [expires: 2023-07-01]
          #             E1D6ABB63BFCFB4BA02FDF1CEC590EEAC9189250
          gpg --keyserver keys.gentoo.org --recv-keys DCD05B71EAB94199527F44ACDB6B8C1F96D8BF6D

          # For Stage3 signatures
          #
          # Fingerprint with spaces:
          #
          # pub   rsa4096/BB572E0E2D182910 2009-08-25 [SC] [expires: 2023-07-01]
          #       Key fingerprint = 13EB BDBE DE7A 1277 5DFD  B1BA BB57 2E0E 2D18 2910
          #       uid                 [ unknown] Gentoo Linux Release Engineering (Automated Weekly Release Key) <releng@gentoo.org>
          #       sub   rsa2048/2C44695DB9F6043D 2019-02-23 [S] [expires: 2023-07-01]
          #             Key fingerprint = 534E 4209 AB49 EEE1 C19D  9616 2C44 695D B9F6 043D
          #
          # Fingerprint no spaces:
          #
          # pub   rsa4096/BB572E0E2D182910 2009-08-25 [SC] [expires: 2023-07-01]
          #       13EBBDBEDE7A12775DFDB1BABB572E0E2D182910
          #       uid                 [ unknown] Gentoo Linux Release Engineering (Automated Weekly Release Key) <releng@gentoo.org>
          #       sub   rsa2048/2C44695DB9F6043D 2019-02-23 [S] [expires: 2023-07-01]
          #             534E4209AB49EEE1C19D96162C44695DB9F6043D
          #
          gpg --keyserver keys.gentoo.org --recv-keys 13EBBDBEDE7A12775DFDB1BABB572E0E2D182910

          gpg --list-public-keys
          gpg --list-public-keys --with-subkey-fingerprint
          gpg --list-public-keys --with-subkey-fingerprint --fingerprint
          # we just need the key, we don't need to sign/trust it

      - name: üë∑ Kubler Get Latest Portage Date
        run: |
          export TERM
          PORTAGE_DATE=$(kubler portage)
          echo "PORTAGE_DATE=$PORTAGE_DATE" >> $GITHUB_ENV

      - name: üë∑ Kubler Set kubler.conf PORTAGE_DATE
        run: |
          grep PORTAGE_DATE kubler.conf || true
          echo "PORTAGE_DATE=$PORTAGE_DATE" >> kubler.conf

      - name: üë∑ Kubler Set kubler.conf IMAGE_TAG
        run: |
          grep IMAGE_TAG kubler.conf || true
          echo "IMAGE_TAG=$PORTAGE_DATE" >> kubler.conf

      - name: üë∑ Check Kubler Downloads
        run: |
          ls -l ~/.kubler/downloads/portage* || true

      - name: üîë Check GPG
        run: |
          gpg --list-public-keys
          ls -l ~/.kubler/downloads/portage-"${PORTAGE_DATE}".* || true
          if [ -e ~/.kubler/downloads/portage-"${PORTAGE_DATE}".tar.xz.gpgsig ] && [ -e ~/.kubler/downloads/portage-"${PORTAGE_DATE}".tar.xz ]; then
            gpg --verify ~/.kubler/downloads/portage-"${PORTAGE_DATE}".tar.xz.gpgsig ~/.kubler/downloads/portage-"${PORTAGE_DATE}".tar.xz
          else
            echo "[!] No files to verify"
          fi

      - name: üêãüç≥ Docker Bake Kubler - images before baking
        run: |
          docker images

      - name: Check env before exposing GitHub Runtime - grep
        run: |
          env | grep ^ACTIONS

      - name: Check env before exposing GitHub Runtime - full
        run: |
          env

      # Needed for bake-action to use GHA cache
      # XXX I think this may be a bit dangerous, exposing secrets to everything in the job
      - name: Expose GitHub Runtime
        #if: ${{ false }}
        uses: crazy-max/ghaction-github-runtime@v3

      - name: Check env after exposed GitHub Runtime - grep
        run: |
          env | grep ^ACTIONS

      - name: Check env after exposed GitHub Runtime - full
        run: |
          env

      - name: üêã Docker Pull Portage
        id: portage-pull
        continue-on-error: true
        run: |
          set -eu
          docker pull "$PORTAGE_IMAGE"

      - name: üêã Docker Pull stage3
        id: stage3-pull
        continue-on-error: true
        run: |
          set -eu
          docker pull "$STAGE3_IMAGE"

      - name: üêã Docker Pull stage3 musl
        id: stage3-musl-pull
        continue-on-error: true
        run: |
          set -eu
          docker pull "$STAGE3_MUSL_IMAGE"

      - name: üêã Docker Pull bob-core
        id: bob-core-pull
        continue-on-error: true
        run: |
          set -eu
          docker pull "$BOB_CORE_IMAGE"

      - name: üêã Docker Pull bob-musl-core
        id: bob-musl-core-pull
        continue-on-error: true
        run: |
          set -eu
          docker pull "$BOB_MUSL_CORE_IMAGE"

      - name: üêãüç≥ Docker Bake Kubler - images bob-core
        run: |
          docker images

      - name: üêã Docker Build kubler builder - bob - set ENV vars
        run: |
          set -eux
          TMP_BOB_IMAGE=ghcr.io/"${GITHUB_REPOSITORY}"/tmp/bob:"${PORTAGE_DATE}"
          echo "TMP_BOB_IMAGE=$TMP_BOB_IMAGE" >> $GITHUB_ENV
          BOB_IMAGE=ghcr.io/"${GITHUB_REPOSITORY}"/bob:"${PORTAGE_DATE}"
          echo "BOB_IMAGE=$BOB_IMAGE" >> $GITHUB_ENV
          TMP_BOB_MUSL_IMAGE=ghcr.io/"${GITHUB_REPOSITORY}"/tmp/bob-musl:"${PORTAGE_DATE}"
          echo "TMP_BOB_MUSL_IMAGE=$TMP_BOB_MUSL_IMAGE" >> $GITHUB_ENV
          BOB_MUSL_IMAGE=ghcr.io/"${GITHUB_REPOSITORY}"/bob-musl:"${PORTAGE_DATE}"
          echo "BOB_MUSL_IMAGE=$BOB_MUSL_IMAGE" >> $GITHUB_ENV

      - name: üêã Docker Pull bob
        id: bob-pull
        continue-on-error: true
        run: |
          set -eu
          docker pull "$BOB_IMAGE"

      - name: üêã Docker Pull bob-musl
        id: bob-musl-pull
        continue-on-error: true
        run: |
          set -eu
          docker pull "$BOB_MUSL_IMAGE"

      - name: üêã Docker Build kubler builder - bob
        if: ${{ false }}
        run: |
          set -eux
          # Build kubler builder outside of kubler with native Docker tools
          # So that we can use the buildkit docker-container driver that supports GHA caching
          cd builder/bob || exit 1
          # This dockerfile does similar to what kubler does to build a builder
          # Difference is kubler uses docker run and mounts volumes, and then commits the container as an image
          # We are building direct, so can't use volumes.
          # I am hoping caching makes up for that.
          docker buildx build \
            --push \
            -f Dockerfile.berney \
            --build-arg PARENT="${BOB_CORE_IMAGE}" \
            -t "${TMP_BOB_IMAGE}" \
            .

      - name: üêã Docker Build kubler builder - bob - list targets
        if: ${{ steps.bob-pull.outcome == 'failure' }}
        uses: docker/bake-action/subaction/list-targets@v4
        with:
          workdir: builder/bob

      - name: üêãüç≥ Docker Bake Kubler builder - bob
        if: ${{ steps.bob-pull.outcome == 'failure' }}
        uses: docker/bake-action@v4
        with:
          workdir: builder/bob
          push: true
          set: |
            bob.args.BASE_IMAGE=${{ env.BOB_CORE_IMAGE }}
            bob.tags=${{ env.TMP_BOB_IMAGE }}
            bob.cache-from=type=gha,scope=portage
            bob.cache-from=type=gha,scope=stage3-hardened-nomultilib
            bob.cache-from=type=gha,scope=bob-core
            bob.cache-from=type=gha,scope=bob
            bob.cache-to=type=gha,scope=bob

      - name: üêã Docker Build kubler builder - bob - test
        run: |
          set -eux
          docker run --rm "${TMP_BOB_IMAGE}" cat /etc/gentoo-release
          docker run --rm "${TMP_BOB_IMAGE}" sh -c "grep -E 'Latest|stage3' /latest-stage3*.txt"
          docker run --rm "${TMP_BOB_IMAGE}" eselect profile show
          docker run --rm "${TMP_BOB_IMAGE}" ls -l /var/cache
          docker run --rm "${TMP_BOB_IMAGE}" ls -l /var/cache/eix
          docker run --rm "${TMP_BOB_IMAGE}" eix --selected -c
          cd builder/bob || exit 1
          CONTAINER_MODE=entrypoint dgoss run -w /goss --entrypoint /goss/goss "${TMP_BOB_IMAGE}" validate --format documentation --color

      - name: üêãüç≥ Docker Bake Kubler builder - bob - oras cp
        if: ${{ steps.bob-pull.outcome == 'failure' }}
        run: |
          set -eux
          oras cp -v "$TMP_BOB_IMAGE" "$BOB_IMAGE"

      - name: üêã Docker Build kubler builder - bob-musl
        if: ${{ false }}
        run: |
          set -eux
          # Build kubler builder outside of kubler with native Docker tools
          # So that we can use the buildkit docker-container driver that supports GHA caching
          cd builder/bob-musl || exit 1
          # This dockerfile does similar to what kubler does to build a builder
          # Difference is kubler uses docker run and mounts volumes, and then commits the container as an image
          # We are building direct, so can't use volumes.
          # I am hoping caching makes up for that.
          docker buildx build \
            --push \
            -f Dockerfile.berney \
            --build-arg PARENT="${BOB_MUSL_CORE_IMAGE}" \
            -t "${TMP_BOB_MUSL_IMAGE}" \
            .

      - name: üêãüç≥ Docker Bake Kubler builder - bob-musl
        if: ${{ steps.bob-musl-pull.outcome == 'failure' }}
        uses: docker/bake-action@v4
        with:
          workdir: builder/bob-musl
          push: true
          set: |
            bob-musl.args.BASE_IMAGE=${{ env.BOB_MUSL_CORE_IMAGE }}
            bob-musl.tags=${{ env.TMP_BOB_MUSL_IMAGE }}
            bob-musl.cache-from=type=gha,scope=portage
            bob-musl.cache-from=type=gha,scope=stage3-musl-hardened
            bob-musl.cache-from=type=gha,scope=bob-musl-core
            bob-musl.cache-from=type=gha,scope=bob-musl
            bob-musl.cache-to=type=gha,scope=bob-musl


      - name: üêã Docker Build kubler builder - bob-musl - test
        run: |
          set -eux
          docker run --rm "${TMP_BOB_MUSL_IMAGE}" cat /etc/gentoo-release
          docker run --rm "${TMP_BOB_MUSL_IMAGE}" sh -c "grep -E 'Latest|stage3' /latest-stage3*.txt"
          docker run --rm "${TMP_BOB_MUSL_IMAGE}" eselect profile show
          docker run --rm "${TMP_BOB_MUSL_IMAGE}" ls -l /var/cache
          docker run --rm "${TMP_BOB_MUSL_IMAGE}" ls -l /var/cache/eix
          docker run --rm "${TMP_BOB_MUSL_IMAGE}" eix --selected -c
          cd builder/bob-musl || exit 1
          CONTAINER_MODE=entrypoint dgoss run -w /goss --entrypoint /goss/goss "${TMP_BOB_MUSL_IMAGE}" validate --format documentation --color

      - name: üêãüç≥ Docker Bake Kubler builder - bob-musl - oras cp
        if: ${{ steps.bob-musl-pull.outcome == 'failure' }}
        run: |
          set -eux
          oras cp -v "$TMP_BOB_MUSL_IMAGE" "$BOB_MUSL_IMAGE"

      - name: üêãüç≥ Docker Images
        run: |
          docker images

      - name: üêãüç≥ Docker Tag Images for Kubler Compatability
        run: |
          # We need a local copy to tag
          # We build tmp image and use oras to copy it, so we don't have it locally
          docker pull "${PORTAGE_IMAGE}"
          docker pull "${BOB_CORE_IMAGE}"
          docker pull "${BOB_MUSL_CORE_IMAGE}"
          docker pull "${BOB_IMAGE}"
          docker pull "${BOB_MUSL_IMAGE}"
          docker tag "${PORTAGE_IMAGE}" kubler-gentoo/portage:latest
          docker tag "${BOB_CORE_IMAGE}" kubler/bob-core:"${PORTAGE_DATE}"
          docker tag "${BOB_MUSL_CORE_IMAGE}" kubler/bob-musl-core:"${PORTAGE_DATE}"
          docker tag "${BOB_IMAGE}" kubler/bob:"${PORTAGE_DATE}"
          docker tag "${BOB_MUSL_IMAGE}" kubler/bob-musl:"${PORTAGE_DATE}"
          docker images

      - name: üêãüç≥ Docker Images
        run: |
          docker images

      - name: üë∑ Kubler Set kubler.conf DEFAULT_MUSL_BUILDER
        #if: ${{ false }}
        run: |
          # If we don't set the default musl builder, some images will fallback to using bob (glibc) builder
          grep DEFAULT_MUSL_BUILDER kubler.conf || true
          #echo "DEFAULT_MUSL_BUILDER=$BOB_MUSL_IMAGE" >> kubler.conf
          # Kubler doesn't understand fully qualified names
          # Gets error `fatal: Couldn't read namespace conf /kubler.conf`
          # We have retagged images to have compat names
          echo "DEFAULT_MUSL_BUILDER=kubler/bob-musl" >> kubler.conf

      - name: üë∑ Portage Container - eix-update - Populate /var/cache/eix
        run: |
          set -u
          # Kubler building builders would use volume from portage container
          # and run `eix-update` which would populate /var/cache/eix.
          # But I'm building the builders directly with docker
          # Docker build doesn't support mounting volumes during builds
          # When using `kubler build` to build images with our builder,
          # the builds fail with this error:
          #
          #   cannot open database file /var/cache/eix/portage.eix for reading
          #
          # So this step will fix this to make kubler build for images happy.
          # kubler does `docker run`, but I think `docker create` is more idiomatic
          docker create --name kubler-gentoo-portage "${PORTAGE_IMAGE}" true
          docker run --rm --volumes-from kubler-gentoo-portage "${BOB_MUSL_IMAGE}" ls -l /var/cache
          docker run --rm --volumes-from kubler-gentoo-portage "${BOB_MUSL_IMAGE}" ls -l /var/cache/eix
          docker run --rm --volumes-from kubler-gentoo-portage "${BOB_MUSL_IMAGE}" eix-update
          docker run --rm --volumes-from kubler-gentoo-portage "${BOB_MUSL_IMAGE}" ls -l /var/cache
          docker run --rm --volumes-from kubler-gentoo-portage "${BOB_MUSL_IMAGE}" ls -l /var/cache/eix

      - name: üöß Build Images - berney/busybox
        #if: ${{ false }}
        id: busybox
        continue-on-error: true
        run: |
          echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          # This is my copy with small changes
          kubler build -v busybox

      - name: Test Image - berney/busybox
        id: test-busybox
        continue-on-error: true
        run: |
          cd images/busybox || false
          echo "kubler=test" >> $GITHUB_OUTPUT
          CONTAINER_MODE=entrypoint dgoss run -w /goss --entrypoint /goss/goss kubler-images/busybox validate --format documentation --color

      - name: üöß Build Images - kubler/busybox
        #if: ${{ false }}
        id: kubler-busybox
        continue-on-error: true
        run: |
          echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          kubler build -v kubler/busybox

      - name: Test Image - kubler/busybox
        id: test-kubler-busybox
        continue-on-error: true
        run: |
          cd images/busybox || false
          echo "kubler=test" >> $GITHUB_OUTPUT
          CONTAINER_MODE=entrypoint dgoss run -w /goss --entrypoint /goss/goss kubler/busybox validate --format documentation --color

      #- name: üõë STOP HERE
      #  run: |
      #    false

      - name: üöß Build Images - kubler/glibc
        #if: ${{ false }}
        id: glibc
        continue-on-error: true
        run: |
          echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          kubler build -v kubler/glibc

      - name: Test Image - kubler/glibc
        id: test-kubler-glibc
        continue-on-error: true
        run: |
          cd images/glibc || false
          echo "kubler=test" >> $GITHUB_OUTPUT
          CONTAINER_MODE=entrypoint dgoss run -w /goss --entrypoint /goss/goss kubler/glibc validate --format documentation --color

      - name: üöß Build Images - figlet
        #if: ${{ false }}
        id: figlet
        continue-on-error: true
        run: |
          echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          kubler build -v figlet

      - name: Test Image - figlet
        id: test-figlet
        continue-on-error: true
        run: |
          cd images/figlet || false
          echo "kubler=test" >> $GITHUB_OUTPUT
          CONTAINER_MODE=entrypoint dgoss run -w /goss --entrypoint /goss/goss kubler-images/figlet validate --format documentation --color

      - name: üöß Build Images - figlet-user
        #if: ${{ false }}
        id: figlet-user
        continue-on-error: true
        run: |
          echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          kubler build -v figlet-user

      - name: Test Image - figlet-user
        id: test-figlet-user
        continue-on-error: true
        run: |
          cd images/figlet-user || false
          echo "kubler=test" >> $GITHUB_OUTPUT
          CONTAINER_MODE=entrypoint dgoss run -w /goss --entrypoint /goss/goss kubler-images/figlet-user validate --format documentation --color

      - name: üöß Build Images - figlet-musl
        #if: ${{ false }}
        id: figlet-musl
        continue-on-error: true
        run: |
          echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          kubler build -v figlet-musl

      - name: Test Image - figlet-musl
        id: test-figlet-musl
        continue-on-error: true
        run: |
          cd images/figlet-musl || false
          echo "kubler=test" >> $GITHUB_OUTPUT
          CONTAINER_MODE=entrypoint dgoss run -w /goss --entrypoint /goss/goss kubler-images/figlet-musl validate --format documentation --color

      - name: üöß Build Images - figlet-musl-static
        #if: ${{ false }}
        id: figlet-musl-static
        continue-on-error: true
        run: |
          echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          kubler build -v figlet-musl-static

      - name: Test Image - figlet-musl-static
        id: test-figlet-musl-static
        continue-on-error: true
        run: |
          cd images/figlet-musl-static || false
          echo "kubler=test" >> $GITHUB_OUTPUT
          CONTAINER_MODE=entrypoint dgoss run -w /goss --entrypoint /goss/goss kubler-images/figlet-musl-static validate --format documentation --color

      - name: üöß Build Images - goss
        #if: ${{ false }}
        id: goss
        continue-on-error: true
        run: |
          echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          kubler build -v goss

      - name: Test Image - goss
        id: test-goss
        continue-on-error: true
        run: |
          cd images/goss || false
          echo "kubler=test" >> $GITHUB_OUTPUT
          # Because the image is already using `/goss` (and it's a file), we need `dgoss` to use a different directory
          # I've added teh `CONTAINER_GOSS_PATH` env var to allow overriding the default
          CONTAINER_MODE=entrypoint CONTAINER_GOSS_PATH=/goss2 dgoss run -w /goss2 --entrypoint /goss2/goss kubler-images/goss validate --format documentation --color

      - name: üöß Build Images - fd
        #if: ${{ false }}
        id: fd
        continue-on-error: true
        run: |
          echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          kubler build -v fd

      - name: Test Image - fd
        id: test-fd
        continue-on-error: true
        run: |
          cd images/fd || false
          echo "kubler=test" >> $GITHUB_OUTPUT
          CONTAINER_MODE=entrypoint dgoss run -w /goss --entrypoint /goss/goss kubler-images/fd validate --format documentation --color

      - name: üöß Build Images - s6
        #if: ${{ false }}
        id: s6
        continue-on-error: true
        run: |
          echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          kubler build -v s6

      - name: Test Image - s6
        id: test-s6
        continue-on-error: true
        run: |
          cd images/s6 || false
          echo "kubler=test" >> $GITHUB_OUTPUT
          CONTAINER_MODE=entrypoint dgoss run -w /goss --entrypoint /goss/goss kubler-images/s6 validate --format documentation --color

      - name: üöß Build Images - s6 - push
        #if: ${{ false }}
        id: s6-push
        continue-on-error: true
        run: |
          # The buildx docker-container driver can't pull from the local registry
          # So we need to push the image
          docker tag kubler-images/s6 ghcr.io/berney/kubler-images/s6
          docker push ghcr.io/berney/kubler-images/s6

      - name: üöß Build Images - s6-busybox
        #if: ${{ false }}
        id: s6-busybox
        continue-on-error: true
        run: |
          echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          DOCKER_BUILD_OPTS="--load"\
          " --cache-from=type=gha,scope=s6-busybox"\
          " --cache-to=type=gha,scope=s6-busybox" \
          kubler build -v s6-busybox

      - name: Test Image - s6-busybox
        id: test-s6-busybox
        continue-on-error: true
        run: |
          cd images/s6-busybox || false
          echo "kubler=test" >> $GITHUB_OUTPUT
          # ash needs a terminal to start
          dgoss run -t kubler-images/s6-busybox

      - name: üöß Build Images - s6-busybox - push
        #if: ${{ false }}
        id: s6-busybox-push
        continue-on-error: true
        run: |
          # The buildx docker-container driver can't pull from the local registry
          # So we need to push the image
          docker tag kubler-images/s6-busybox ghcr.io/berney/kubler-images/s6-busybox
          docker push ghcr.io/berney/kubler-images/s6-busybox

      # This is based off s6
      - name: üöß Build Images - coturn
        #if: ${{ false }}
        id: coturn
        continue-on-error: true
        run: |
          echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          # To continue the string, no spaces between end quote,slash, EOL, or start of line
          # e.g. as a stream its `"alpha"\\\n" omega"\\\n"
          DOCKER_BUILD_OPTS="--load"\
          " --cache-from=type=gha,scope=coturn"\
          " --cache-to=type=gha,scope=coturn" \
            kubler build -v coturn

      - name: üöß Build Images - s6-coturn-busybox
        #if: ${{ false }}
        id: s6-coturn-busybox
        continue-on-error: true
        run: |
          echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          DOCKER_BUILD_OPTS="--load"\
          " --cache-from=type=gha,scope=coturn"\
          " --cache-from=type=gha,scope=s6-busybox"\
          " --cache-from=type=gha,scope=s6-coturn-busybox"\
          " --cache-to=type=gha,scope=s6-coturn-busybox" \
            kubler build -v s6-coturn-busybox

      - name: üöß Build Images - nmap
        #if: ${{ false }}
        id: nmap
        continue-on-error: true
        run: |
          echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          DOCKER_BUILD_OPTS="--load"\
          " --cache-from=type=gha,scope=nmap"\
          " --cache-to=type=gha,scope=nmap" \
            kubler build -v nmap

      - name: Test Image - nmap
        id: test-nmap
        continue-on-error: true
        run: |
          cd images/nmap || false
          echo "kubler=test" >> $GITHUB_OUTPUT
          docker run --rm kubler-images/nmap -A --open scanme.nmap.org
          CONTAINER_MODE=entrypoint dgoss run -w /goss --entrypoint /goss/goss kubler-images/nmap -l debug validate --format documentation --color

      - name: üöß Build Images - nmap-musl-static
        #if: ${{ false }}
        id: nmap-musl-static
        continue-on-error: true
        run: |
          echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          DOCKER_BUILD_OPTS="--load"\
          " --cache-from=type=gha,scope=nmap-musl-static"\
          " --cache-to=type=gha,scope=nmap-musl-static" \
            kubler build -v nmap-musl-static

      - name: üöß Build Images - tmux
        #if: ${{ false }}
        id: tmux
        continue-on-error: true
        run: |
          echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          DOCKER_BUILD_OPTS="--load"\
          " --cache-from=type=gha,scope=tmux"\
          " --cache-to=type=gha,scope=tmux" \
            kubler build -v tmux

      - name: üöß Build Images - Everything excluding Problematic
        #if: ${{ false }}
        id: everything-exc-problematic
        continue-on-error: true
        run: |
          #echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          kubler build kubler-images -e kubler-images/nmap-musl-static

      - name: üöß Build Images - EVERYTHING
        if: ${{ false }}
        id: everything
        continue-on-error: true
        run: |
          #echo "kubler=build" >> $GITHUB_OUTPUT
          export TERM
          kubler build kubler-images

      - name: üîé Post Build Inspect
        env:
          # This will contain double-quotes, which `echo` would eat, breaking `jq`
          # https://stackoverflow.com/a/72955840
          STEPS: ${{ toJSON(steps) }}
        run: |
          docker images
          docker ps -a
          df -h
          git status
          git ls-files -o
          ls -ld ~/.kubler
          ls -la ~/.kubler
          ls -ld ~/.kubler/log
          ls -la ~/.kubler/log
          ls -l ~/.kubler/log/build.log || true
          cat ~/.kubler/log/build.log || true
          echo "== Steps"
          printf '%s\n' "$STEPS"
          echo "== Steps | jq"
          printf '%s\n' "$STEPS" | jq .
          echo "== Steps | jq expr"
          printf '%s\n' "$STEPS" | jq 'to_entries | map(select(.value.outputs.kubler == "build").key)'

      - name: üîé Sumarise Build Status
        env:
          # This will contain double-quotes, which `echo` would eat, breaking `jq`
          # https://stackoverflow.com/a/72955840
          STEPS: ${{ toJSON(steps) }}
        run: |
          echo "# Successful Build Steps"
          printf '%s\n' "$STEPS" | jq -r 'to_entries | map(select(.value | .outputs.kubler == "build" and .outcome == "success").key | sub("^"; "* ")) | join("\n")'
          echo "# Failed Build Steps"
          printf '%s\n' "$STEPS" | jq -r 'to_entries | map(select(.value | .outputs.kubler == "build" and .outcome != "success").key | sub("^"; "* ")) | join("\n")'

          echo "# Successful Build Steps" >> $GITHUB_STEP_SUMMARY
          printf '%s\n' "$STEPS" | jq -r 'to_entries | map(select(.value | .outputs.kubler == "build" and .outcome == "success").key | sub("^"; "* ")) | join("\n")' >> $GITHUB_STEP_SUMMARY
          echo "# Failed Build Steps" >> $GITHUB_STEP_SUMMARY
          printf '%s\n' "$STEPS" | jq -r 'to_entries | map(select(.value | .outputs.kubler == "build" and .outcome != "success").key | sub("^"; "* ")) | join("\n")' >> $GITHUB_STEP_SUMMARY

      - name: üîé Sumarise Test Status
        env:
          # This will contain double-quotes, which `echo` would eat, breaking `jq`
          # https://stackoverflow.com/a/72955840
          STEPS: ${{ toJSON(steps) }}
        run: |
          echo "# Successful Test Steps"
          printf '%s\n' "$STEPS" | jq -r 'to_entries | map(select(.value | .outputs.kubler == "test" and .outcome == "success").key | sub("^"; "* ")) | join("\n")'
          echo "# Failed Test Steps"
          printf '%s\n' "$STEPS" | jq -r 'to_entries | map(select(.value | .outputs.kubler == "test" and .outcome != "success").key | sub("^"; "* ")) | join("\n")'

          echo "# Successful Test Steps" >> $GITHUB_STEP_SUMMARY
          printf '%s\n' "$STEPS" | jq -r 'to_entries | map(select(.value | .outputs.kubler == "test" and .outcome == "success").key | sub("^"; "* ")) | join("\n")' >> $GITHUB_STEP_SUMMARY
          echo "# Failed Test Steps" >> $GITHUB_STEP_SUMMARY
          printf '%s\n' "$STEPS" | jq -r 'to_entries | map(select(.value | .outputs.kubler == "test" and .outcome != "success").key | sub("^"; "* ")) | join("\n")' >> $GITHUB_STEP_SUMMARY

      - run: echo "üçè This job's status is ${{ job.status }}."
